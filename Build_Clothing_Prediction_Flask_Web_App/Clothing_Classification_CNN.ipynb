{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Clothing_Classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAqvSV-zFm19",
        "colab_type": "text"
      },
      "source": [
        "### Clothing_Apparel_Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbjOWtxJFm2N",
        "colab_type": "code",
        "outputId": "552d6023-d4de-4630-999b-67f6f858fb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#Import necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlPlQtdG1Ev",
        "colab_type": "code",
        "outputId": "b385b12e-7ec1-42a3-c582-2d6b85854a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Load fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 9us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbs2QA6qFm26",
        "colab_type": "code",
        "outputId": "be72fb98-843d-49db-85c4-8889e6f0bf3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Explore the dataset\n",
        "# Check the shape and size of x_train, x_test, y_train, y_test\n",
        "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
        "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
        "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples/observations in training data: 60000\n",
            "Number of labels in training data: 60000\n",
            "Dimensions of a single image in x_train:(28, 28)\n",
            "-------------------------------------------------------------\n",
            "Number of samples/observations in test data: 10000\n",
            "Number of labels in test data: 10000\n",
            "Dimensions of single image in x_test:(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdXkB2axFm3N",
        "colab_type": "text"
      },
      "source": [
        "### View sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7IrFmtbFm3Q",
        "colab_type": "code",
        "outputId": "253204bc-a740-4d7b-d3c0-f7e6db913c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "# Visualization library to visualize images \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
        "# Color map is set to grey since our image dataset is grayscale\n",
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(232)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(233)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(234)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(235)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD6CAYAAAC4RRw1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRQu4IQQkihcwAkhJFH+H7zqIdcTBBpmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kOiUxZ1Fm3f",
        "colab_type": "text"
      },
      "source": [
        "### Let's create our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCR3JawFm3k",
        "colab_type": "code",
        "outputId": "41a5a6f6-41f9-490d-dc8b-c37b94713725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Import necessary keras specific libraries\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "# Setting Training Parameters like batch_size, epochs\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "# Storing the number of rows and columns\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
        "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
        "to (60000,28,28,1)'''\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Storing the shape of a single image \n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Changing image type to float32 data type\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Calculate the number of classes and number of pixels \n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Number of Classes: 10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,200,778\n",
            "Trainable params: 1,200,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzoS-5OcFm3w",
        "colab_type": "text"
      },
      "source": [
        "### Let's train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bACuyHMEFm3y",
        "colab_type": "code",
        "outputId": "52115174-f497-4ff2-c322-b4fc704d5833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_fitting = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 16s 262us/step - loss: 0.4566 - acc: 0.8443 - val_loss: 0.3106 - val_acc: 0.8898\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.2915 - acc: 0.8955 - val_loss: 0.2612 - val_acc: 0.9045\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.2438 - acc: 0.9135 - val_loss: 0.2450 - val_acc: 0.9109\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.2139 - acc: 0.9233 - val_loss: 0.2584 - val_acc: 0.9096\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.1891 - acc: 0.9320 - val_loss: 0.2530 - val_acc: 0.9130\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.1740 - acc: 0.9374 - val_loss: 0.2451 - val_acc: 0.9146\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1605 - acc: 0.9406 - val_loss: 0.2168 - val_acc: 0.9257\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1459 - acc: 0.9470 - val_loss: 0.2170 - val_acc: 0.9243\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1338 - acc: 0.9510 - val_loss: 0.2202 - val_acc: 0.9244\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1238 - acc: 0.9550 - val_loss: 0.2347 - val_acc: 0.9253\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1180 - acc: 0.9564 - val_loss: 0.2152 - val_acc: 0.9267\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1113 - acc: 0.9596 - val_loss: 0.2399 - val_acc: 0.9269\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.1047 - acc: 0.9626 - val_loss: 0.2270 - val_acc: 0.9217\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0981 - acc: 0.9645 - val_loss: 0.2295 - val_acc: 0.9215\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0917 - acc: 0.9671 - val_loss: 0.2508 - val_acc: 0.9274\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0873 - acc: 0.9685 - val_loss: 0.2677 - val_acc: 0.9297\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0835 - acc: 0.9697 - val_loss: 0.3250 - val_acc: 0.9288\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0793 - acc: 0.9717 - val_loss: 0.2194 - val_acc: 0.9272\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0766 - acc: 0.9723 - val_loss: 0.2886 - val_acc: 0.9278\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0729 - acc: 0.9739 - val_loss: 0.3249 - val_acc: 0.9290\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0723 - acc: 0.9747 - val_loss: 0.2792 - val_acc: 0.9233\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0689 - acc: 0.9748 - val_loss: 0.2832 - val_acc: 0.9258\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0663 - acc: 0.9763 - val_loss: 0.2672 - val_acc: 0.9312\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0643 - acc: 0.9769 - val_loss: 0.2486 - val_acc: 0.9235\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0597 - acc: 0.9789 - val_loss: 0.2632 - val_acc: 0.9276\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0558 - acc: 0.9806 - val_loss: 0.2486 - val_acc: 0.9287\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0590 - acc: 0.9788 - val_loss: 0.2578 - val_acc: 0.9253\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0570 - acc: 0.9791 - val_loss: 0.2721 - val_acc: 0.9315\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0549 - acc: 0.9801 - val_loss: 0.2584 - val_acc: 0.9329\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0531 - acc: 0.9811 - val_loss: 0.2308 - val_acc: 0.9249\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0514 - acc: 0.9819 - val_loss: 0.2577 - val_acc: 0.9285\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0488 - acc: 0.9822 - val_loss: 0.3385 - val_acc: 0.9332\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0510 - acc: 0.9820 - val_loss: 0.3107 - val_acc: 0.9317\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0468 - acc: 0.9838 - val_loss: 0.3252 - val_acc: 0.9304\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0477 - acc: 0.9826 - val_loss: 0.3261 - val_acc: 0.9314\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0459 - acc: 0.9832 - val_loss: 0.3555 - val_acc: 0.9312\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 9s 149us/step - loss: 0.0454 - acc: 0.9838 - val_loss: 0.2954 - val_acc: 0.9308\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0435 - acc: 0.9847 - val_loss: 0.2902 - val_acc: 0.9275\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0441 - acc: 0.9841 - val_loss: 0.2425 - val_acc: 0.9294\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0432 - acc: 0.9847 - val_loss: 0.3200 - val_acc: 0.9320\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0427 - acc: 0.9853 - val_loss: 0.3413 - val_acc: 0.9295\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0406 - acc: 0.9859 - val_loss: 0.2875 - val_acc: 0.9280\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0393 - acc: 0.9861 - val_loss: 0.2909 - val_acc: 0.9315\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0404 - acc: 0.9859 - val_loss: 0.2942 - val_acc: 0.9316\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.3475 - val_acc: 0.9324\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0376 - acc: 0.9871 - val_loss: 0.3034 - val_acc: 0.9318\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0371 - acc: 0.9867 - val_loss: 0.4109 - val_acc: 0.9282\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0390 - acc: 0.9862 - val_loss: 0.3660 - val_acc: 0.9342\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0395 - acc: 0.9863 - val_loss: 0.4100 - val_acc: 0.9312\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0373 - acc: 0.9872 - val_loss: 0.2971 - val_acc: 0.9317\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0365 - acc: 0.9874 - val_loss: 0.2842 - val_acc: 0.9351\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0353 - acc: 0.9878 - val_loss: 0.3658 - val_acc: 0.9331\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0370 - acc: 0.9869 - val_loss: 0.4826 - val_acc: 0.9314\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0343 - acc: 0.9880 - val_loss: 0.3274 - val_acc: 0.9328\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0328 - acc: 0.9883 - val_loss: 0.4820 - val_acc: 0.9296\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0340 - acc: 0.9880 - val_loss: 0.2767 - val_acc: 0.9327\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0341 - acc: 0.9880 - val_loss: 0.2925 - val_acc: 0.9304\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0335 - acc: 0.9882 - val_loss: 0.4752 - val_acc: 0.9318\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0336 - acc: 0.9886 - val_loss: 0.3032 - val_acc: 0.9321\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0310 - acc: 0.9889 - val_loss: 0.3253 - val_acc: 0.9324\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0321 - acc: 0.9892 - val_loss: 0.3680 - val_acc: 0.9309\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0331 - acc: 0.9884 - val_loss: 0.2640 - val_acc: 0.9172\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0292 - acc: 0.9895 - val_loss: 0.3536 - val_acc: 0.9327\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.3239 - val_acc: 0.9322\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0311 - acc: 0.9898 - val_loss: 0.2598 - val_acc: 0.9249\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0306 - acc: 0.9896 - val_loss: 0.3892 - val_acc: 0.9327\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0292 - acc: 0.9901 - val_loss: 0.3618 - val_acc: 0.9339\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0300 - acc: 0.9898 - val_loss: 0.2707 - val_acc: 0.9269\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0295 - acc: 0.9895 - val_loss: 0.4928 - val_acc: 0.9331\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0276 - acc: 0.9902 - val_loss: 0.3688 - val_acc: 0.9327\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0272 - acc: 0.9907 - val_loss: 0.3638 - val_acc: 0.9324\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0287 - acc: 0.9901 - val_loss: 0.4277 - val_acc: 0.9318\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0296 - acc: 0.9901 - val_loss: 0.3582 - val_acc: 0.9326\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0276 - acc: 0.9904 - val_loss: 0.3459 - val_acc: 0.9289\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0269 - acc: 0.9903 - val_loss: 0.2873 - val_acc: 0.9317\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0292 - acc: 0.9899 - val_loss: 0.4299 - val_acc: 0.9346\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0267 - acc: 0.9910 - val_loss: 0.3170 - val_acc: 0.9335\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0259 - acc: 0.9914 - val_loss: 0.5572 - val_acc: 0.9326\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0273 - acc: 0.9906 - val_loss: 0.3302 - val_acc: 0.9335\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0280 - acc: 0.9904 - val_loss: 0.3866 - val_acc: 0.9346\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0263 - acc: 0.9909 - val_loss: 0.4097 - val_acc: 0.9292\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0258 - acc: 0.9914 - val_loss: 0.4045 - val_acc: 0.9347\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.2614 - val_acc: 0.9171\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.3079 - val_acc: 0.9313\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0275 - acc: 0.9908 - val_loss: 0.4379 - val_acc: 0.9346\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0264 - acc: 0.9913 - val_loss: 0.5257 - val_acc: 0.9310\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0260 - acc: 0.9912 - val_loss: 0.5861 - val_acc: 0.9306\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0259 - acc: 0.9908 - val_loss: 0.4513 - val_acc: 0.9349\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.2797 - val_acc: 0.9315\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0248 - acc: 0.9917 - val_loss: 0.3395 - val_acc: 0.9341\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0249 - acc: 0.9917 - val_loss: 0.5222 - val_acc: 0.9328\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0244 - acc: 0.9913 - val_loss: 0.4732 - val_acc: 0.9331\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.4509 - val_acc: 0.9352\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.4486 - val_acc: 0.9352\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.4511 - val_acc: 0.9340\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0234 - acc: 0.9919 - val_loss: 0.2790 - val_acc: 0.9164\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0256 - acc: 0.9913 - val_loss: 0.4586 - val_acc: 0.9347\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0229 - acc: 0.9916 - val_loss: 0.4937 - val_acc: 0.9345\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0233 - acc: 0.9921 - val_loss: 0.3989 - val_acc: 0.9353\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0233 - acc: 0.9918 - val_loss: 0.4631 - val_acc: 0.9324\n",
            "Test loss: 0.46314503292892184\n",
            "Test accuracy: 0.9324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKJkwl69HW9P",
        "colab_type": "code",
        "outputId": "2cc2a8c2-56b0-446b-dad3-a44b24fc0e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Configuration related preprocessing step before mounting the drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145118 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.17-0ubuntu2~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.17-0ubuntu2~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE9aiDjmHy76",
        "colab_type": "code",
        "outputId": "ed2d28fc-c3c5-4b65-ab7b-fe7e3990f856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BDnAqerJc6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the directory to current working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Youtube_Projects\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmACEqXEYM96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model with the name clothing_classification_model\n",
        "model.save('clothing_classification_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NQr-s4FUuJ7",
        "colab_type": "code",
        "outputId": "c802ebbe-dd1a-4631-e849-c52d4a4a7c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "# Import few more necessary libraries.\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "\t# Load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# Convert the image to array\n",
        "\timg = img_to_array(img)\n",
        "\t# Reshape the image into a sample of 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# Prepare it as pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('sandal.jpg')\n",
        "# Load the saved model\n",
        "model = load_model('clothing_classification_model.h5')\n",
        "# Predict the apparel class\n",
        "class_prediction = model.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "Sandal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVSK19-OFm4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7X24nIDFm4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}